{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOz4wvIYVuyf1VK5BoVxQRw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliNajafpour/AI-Face-Identifier/blob/main/TextAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A0PpCQ5W_Mf",
        "outputId": "ea851c1d-1f0b-466f-e266-0579a06b7739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import os"
      ],
      "metadata": {
        "id": "YoBo4j8rXDzb"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/AliNajafpour/AI-Face-Identifier.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--c4RW_ZubKm",
        "outputId": "e8f46d63-20b1-4daf-b590-2fb985b09f0b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AI-Face-Identifier'...\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 104 (delta 41), reused 37 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (104/104), 348.61 KiB | 1.41 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_answering_generator = transformers.pipeline('question-answering', model='deepset/roberta-base-squad2', device=0)\n",
        "text2text_generator = transformers.pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device=0)\n",
        "ner_generator = transformers.pipeline(\"ner\", grouped_entities=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFIOj9sZYH-r",
        "outputId": "b3e69f15-b5ec-4160-a1e9-19bcb37dccd1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c_VBOJ7e3oAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find the name with NER & text2text & question_answering"
      ],
      "metadata": {
        "id": "o3DXSX4U3o8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_name_with_file(file, question):\n",
        "  with open(file) as f:\n",
        "    text = f.read()\n",
        "  result1 = question_answering_generator(context=text, question=question)\n",
        "  result2 = text2text_generator(f\"who is main person in the text?.\\n\\n {text}\")\n",
        "  result3 = ner_generator(text)\n",
        "  l = []\n",
        "  for r in result3:\n",
        "    if r['entity_group'] == 'PER':\n",
        "      l.append(r['word'])\n",
        "  return  result1,  result2,  max(set(l), key=l.count)\n"
      ],
      "metadata": {
        "id": "po_DeepJbLLS"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name1, name2, name3 = extract_name_with_file('/content/AI-Face-Identifier/test/test_text/text1.txt', 'who is the main person in the texts?')\n",
        "print('model 1 says: ' + name1['answer'], 'model 2 says: '  + name2[0]['generated_text'], 'model 3 says: ' + name3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au-HwUkOf0Vc",
        "outputId": "b0d18129-1e85-4202-f06f-d4edd0cc1d01"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model 1 says: Ayatollah Ali Khamenei model 2 says: President Trump praises Puerto Rico’s response to Hurricane Maria as “an incredible, unsung success model 3 says: Whitehouse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name1, name2, name3 = extract_name_with_file('/content/AI-Face-Identifier/test/test_text/text2.txt', 'who is the main person in the texts?')\n",
        "print('model 1 says: ' + name1['answer'], 'model 2 says: '  + name2[0]['generated_text'], 'model 3 says: ' + name3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlI1_yaLlnNM",
        "outputId": "1a3b179e-8bc4-4508-a94f-665ea63db659"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model 1 says: Schumer model 2 says: Whitehouse says Republicans forced Democrats to choose between supporting a continuing resolution or a government shutdown. model 3 says: Whitehouse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name1, name2, name3 = extract_name_with_file('/content/AI-Face-Identifier/test/test_text/text3.txt', 'who is the main person in the texts?')\n",
        "print('model 1 says: ' + name1['answer'], 'model 2 says: '  + name2[0]['generated_text'], 'model 3 says: ' + name3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAvjyr-iqq3E",
        "outputId": "8328f11d-97a4-4977-9428-ca6186f0fa9a"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model 1 says: Ayatollah Ali Khamenei model 2 says: Summary: China to continue retaliation against US tariffs model 3 says: Trump\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name1, name2, name3 = extract_name_with_file('/content/AI-Face-Identifier/test/test_text/text4.txt', 'who is the main person in the texts?')\n",
        "print('model 1 says: ' + name1['answer'], 'model 2 says: '  + name2[0]['generated_text'], 'model 3 says: ' + name3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abcJVgrhtIP-",
        "outputId": "586368fb-8a8f-4be1-9000-b52c5ec5023e"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model 1 says: President Donald Trump model 2 says: Trump model 3 says: Trump\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name1, name2, name3 = extract_name_with_file('/content/AI-Face-Identifier/test/test_text/text5.txt', 'who is the main person in the texts?')\n",
        "print('model 1 says: ' + name1['answer'], 'model 2 says: '  + name2[0]['generated_text'], 'model 3 says: ' + name3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNw_Bw_aux2-",
        "outputId": "42f138e4-b625-425c-8ef2-dde7b2b3b004"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model 1 says: Kushner model 2 says: Donald Trump model 3 says: Trump\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find the name with NER throu all texts"
      ],
      "metadata": {
        "id": "k07ZvtD-3d4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_name_NER(folder_path):\n",
        "  names = []\n",
        "  for path in os.listdir(folder_path):\n",
        "    if path.lower().endswith('.txt'):\n",
        "        full_path = os.path.join(folder_path, path)\n",
        "        with open(full_path) as f:\n",
        "          text = f.read()\n",
        "        result = ner_generator(text)\n",
        "        file_names = []\n",
        "        for r in result:\n",
        "            if r['entity_group'] == 'PER':\n",
        "              names.append(r['word'])\n",
        "  return max(set(names), key=names.count)"
      ],
      "metadata": {
        "id": "fAAj0l3zvuLY"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_name_NER('/content/AI-Face-Identifier/test/test_text')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lHUbiZtE1HBe",
        "outputId": "51b8100c-e64d-4bbd-a9b9-33224dcea7ef"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Trump'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QgUzAO4L1JHM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}